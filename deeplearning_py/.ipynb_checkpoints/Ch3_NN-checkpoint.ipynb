{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation function:**\n",
    "- Sigmoid function\n",
    "- Relu\n",
    "- 恆等函數\n",
    "\n",
    "**Tips:**\n",
    "> - 回归问题：　用恒等函数\n",
    "- Bi-classifiction 问题：　用sigmoid function\n",
    "- Multi-classification问题：　用softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_function(x):   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorftmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax　out　of boundar**\n",
    "- (0,1)之间的函数\n",
    "- 单调函数\n",
    "- 输出总和为１ --> 可以解释为**机率** \n",
    "   - 神经网络的类别会把相当于输出最大神经元的类别当作辨识结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c) #防止溢位\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.26894142, 0.88079708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**３ layers ＮＮ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    '''\n",
    "    　进行权重W　与　偏权重b 的初始化\n",
    "    '''\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4],[0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3],[0.2,0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "     # 輸入曾:第０曾: x\n",
    "     # 第一曾： hidden layer\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    # 第二層：\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    #第三層：\n",
    "    a3 = np.dot(z2,W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return ｙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31682708, 0.69627909])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network  = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出曾的设计\n",
    "> - softmax function\n",
    "- 輸出曾的神經元數量\n",
    "    - 必須根據要解決的問題而定. \n",
    "       - 類別分類問題: 輸出曾的神經元數量＝分類別數量\n",
    "           - 經典：MIST 辨別手寫數字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network的推論處理: 正向傳播(forward propagation)\n",
    "> Steps 和機器學習相同：　**學習**＆**推理**\n",
    "- trainning data: 學習\n",
    "- 使用學習的參數: 推論; 將輸入資料分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# sys.path(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#data shape: 60,000ｉmages, 10,000ｉmages, 28x28\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    pil_image = Image.fromarray(np.uint8(img))\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "label=t_train[0]\n",
    "print(label)\n",
    "print(img.shape)\n",
    "img = img.reshape(28,28)\n",
    "img.shape\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論處理\n",
    "def get_data():\n",
    "    '''\n",
    "        Data　pre-processing:\n",
    "        normaliztion: data value in (0,1)\n",
    "        \n",
    "    '''\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def ｉnit_network():\n",
    "    with open('sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    '''\n",
    "    W1: (784, 50)\n",
    "    W2: (50, 100)\n",
    "    W3: (50, 10)\n",
    "    '''\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2,W3) + b3\n",
    "    y = softmax(a3) # 分類問題\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n",
      "time: 4.173082590103149\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "before = time.time()\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i]) # shape(10,)\n",
    "    which_group = np.argmax(y) #取得幾率最高的元素的array的ｉndex\n",
    "    if which_group == t[i]:\n",
    "        accuracy_cnt +=1\n",
    "print(\"Accuracy: {}\".format(str(float(accuracy_cnt)/len(x))))\n",
    "\n",
    "after = time.time()\n",
    "print('time: {}'.format(str(after-before)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips: data預先處理　pre-processing**\n",
    "> * data 以０爲中心移動分布\n",
    "* data 分布在一定範圍內，形成正則化regularion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ｂatch-processing 批次處理**\n",
    "> 上面是一張一張的for loop　處理\n",
    " *陣列化運算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n",
      "time: 0.24142217636108398\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "accuracy_cnt_2 = 0\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y = predict(network, x_batch) #shape(100,10)\n",
    "    which_group = np.argmax(y, axis=1)\n",
    "    accuracy_cnt_2 += np.sum(which_group == t[i:i+batch_size])\n",
    "print(\"Accuracy: {}\".format(str(float(accuracy_cnt_2)/len(x))))\n",
    "\n",
    "after = time.time()\n",
    "print('time: {}'.format(str(after-before)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ch4 NＮ的學習目的\n",
    "> **是以損失函數爲基準，　找到最小的權重參數**\n",
    "* Gradient Decent 梯度下降法：　找到最小損失函數值的方法，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 均方误差\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  交叉熵误差\n",
    "# log 以e为底部；\n",
    "# 只计算了对应正确答案标签为1的输出的自然对数\n",
    "def cross_entropy(y,t):\n",
    "    delta = 1e-7 ## becuase np.log(0) == inf 负的无限大\n",
    "    return -np.sum(t * np.log(y+delta))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[2]=1\n",
    "t ## 正确的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([0.1, 0.05,0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n",
    "y2 = np.array([0.1, 0.05,0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "error1= mean_squared_error(y1,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "error2 = mean_squared_error(y2,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "error3 = cross_entropy(y1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "error4 = cross_entropy(y2,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003 0.5975 0.510825457099338 2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "print(error1, error2,error3, error4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵小批次学习\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1: #只有一张\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]  # 大于1的data\n",
    "    return -np.sum(t*np.log(y))/batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "600000\n"
     ]
    }
   ],
   "source": [
    "#小批次学习\n",
    "# 交叉熵小批次学习\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) =load_mnist(normalize =True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.size) # shape[0] * shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42727, 37506,  8667, 36600, 13249, 40369, 13411, 32227, 31541,\n",
       "       33428])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机取出10张影响\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "\n",
    "batch_mask = np.random.choice(train_size, batch_size) \n",
    "batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[[225, 13594]] #取第225和13594张"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数值微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding error\n",
    "def numerical_diff(f, x): # input a function\n",
    "    #h = 10e-50  # np.float32(1e-50)\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) -f(x-h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 梯度\n",
    "def _numerical_gradient_no_batch(f, x): # x is a array\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) #产生和x相同形状的阵列\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # 计算f(x+h)\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)  # f(x+h)\n",
    "        \n",
    "        #计算f(x-h)\n",
    "        x[idx] = float(tmp_val) - h\n",
    "        fxh2 = f(x)  # f(x-h)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) /(2*h)\n",
    "        x[idx] = tmp_val\n",
    "    return grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##批量梯度\n",
    "def numerical_gradient(f, X):\n",
    "    if X.ndim ==1:\n",
    "        return _numerical_gradient_no_batch(f,X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3,5])\n",
    "for idx in range(x.size):\n",
    "    tmp_val = x[idx]\n",
    "    h = 1e-4\n",
    "    x[idx]=tmp_val + h\n",
    "    print(x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad1 = _numerical_gradient_no_batch(function_2, np.array([3.0,4.0]))\n",
    "grad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 梯度法:从目前的位置往梯度方向,之前进一定的距离,同样计算出移动后位置的梯度,在朝着梯度发现前进,重复这个步骤,往梯度发现移动\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, np.array([-3.0,4.0]), lr = 10) # 学习率太大,往大数值扩散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  4.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, np.array([-3.0,4.0]), lr =1e-100) # 学习率太小, 几乎不会更新就结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter: learning rate, 人工设定, 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络的梯度\n",
    "class SimpleNet:\n",
    "    def __init__(self, ):\n",
    "        self.W = np.random.randn(2,3) # 以正态分布初始化\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2545333 ,  0.01522361, -0.19216788],\n",
       "       [ 2.64380823,  1.14799105,  0.60558183]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleNet = SimpleNet()\n",
    "simpleNet.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.22670742, 1.04232611, 0.42972291])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.6,0.9])\n",
    "p = simpleNet.predict(x)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40768251,  0.12472451, -0.53240702],\n",
       "       [ 0.61152376,  0.18708677, -0.79861052]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= np.array([0,0,1])\n",
    "f = lambda W:simpleNet.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, simpleNet.W)\n",
    "dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 双层NN的类别\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        #权重初始化\n",
    "        self.params= {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        \n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t): # correct label\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self, y, t):\n",
    "        y =self.predict(x)\n",
    "        y = np.argmax(y, axis = 1) # each row's index of max value\n",
    "        t = np.argmax(t, axis = 1)\n",
    "        \n",
    "        accuracy = np.sum(y==t)/float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = TwoLayerNet(input_size =784, hidden_size = 100, output_size = 10,)\n",
    "net2.params['W1'].shape\n",
    "net2.params['b1'].shape\n",
    "net2.params['W2'].shape\n",
    "net2.params['b2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100,784) #a uniform distribution over [0, 1)\n",
    "t = np.random.rand(100,10)\n",
    "\n",
    "grads = net2.numerical_gradient(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-2.72935452e-05, -3.54134500e-06,  1.36221097e-04, ...,\n",
       "          1.54871671e-05,  1.45398005e-05, -3.96340738e-07],\n",
       "        [-5.18989651e-05,  2.37824338e-05,  7.22022619e-05, ...,\n",
       "          5.07881737e-06,  3.40227402e-05, -4.44444481e-07],\n",
       "        [-4.98305397e-05, -5.19410293e-06, -6.55517240e-05, ...,\n",
       "          1.23575177e-04,  1.08883000e-04, -5.37880496e-05],\n",
       "        ...,\n",
       "        [ 7.26167571e-06, -3.41004380e-05,  6.83048285e-06, ...,\n",
       "         -4.50675941e-06,  1.43363827e-04,  7.05024306e-05],\n",
       "        [-9.94757698e-05, -5.20986276e-05,  4.67218797e-05, ...,\n",
       "          1.60925140e-05,  1.72591506e-04,  2.51558063e-05],\n",
       "        [-3.90947719e-06,  1.30217259e-05,  2.39581865e-05, ...,\n",
       "          1.74000547e-05,  2.61463384e-05,  1.98756567e-05]]),\n",
       " 'W2': array([[ 1.98228086e-03,  1.77070621e-02,  7.85227002e-03,\n",
       "         -6.79144211e-03, -1.32433630e-02,  1.40206787e-02,\n",
       "         -1.54260409e-03, -1.17574936e-02, -1.61617368e-02,\n",
       "          1.03632764e-02],\n",
       "        [ 1.08886304e-04,  1.94186841e-02,  6.51169117e-03,\n",
       "         -5.60101128e-03, -1.44040968e-02,  1.49981640e-02,\n",
       "         -1.59429298e-03, -1.18520267e-02, -1.68519085e-02,\n",
       "          1.09849956e-02],\n",
       "        [ 9.25547496e-04,  1.75582457e-02,  7.24322881e-03,\n",
       "         -5.26586014e-03, -1.15734102e-02,  1.33159684e-02,\n",
       "         -2.11639037e-03, -1.22598161e-02, -1.65145532e-02,\n",
       "          9.30471078e-03],\n",
       "        [ 6.42677556e-04,  1.81638173e-02,  7.42193482e-03,\n",
       "         -5.38437178e-03, -1.35680381e-02,  1.36722975e-02,\n",
       "         -1.12586726e-03, -1.13740404e-02, -1.67707406e-02,\n",
       "          1.03194198e-02],\n",
       "        [ 1.56089076e-03,  2.25062219e-02,  6.69206582e-03,\n",
       "         -7.47959046e-03, -1.64855827e-02,  1.59674189e-02,\n",
       "         -2.50923478e-03, -1.40117960e-02, -1.89568273e-02,\n",
       "          1.12870750e-02],\n",
       "        [ 1.06956993e-03,  2.07696025e-02,  7.78365305e-03,\n",
       "         -6.14865154e-03, -1.49909581e-02,  1.43156666e-02,\n",
       "         -2.70214510e-03, -1.33656198e-02, -1.82731338e-02,\n",
       "          1.02464380e-02],\n",
       "        [ 1.12119299e-03,  1.72907902e-02,  5.68067119e-03,\n",
       "         -5.63478817e-03, -1.39159001e-02,  1.31155625e-02,\n",
       "         -1.96353351e-03, -1.19886569e-02, -1.58523909e-02,\n",
       "          9.33401161e-03],\n",
       "        [ 8.07061902e-04,  2.06135644e-02,  7.90403842e-03,\n",
       "         -4.86233237e-03, -1.39102795e-02,  1.45666459e-02,\n",
       "         -2.22340486e-03, -1.23275007e-02, -1.74014635e-02,\n",
       "          1.00117459e-02],\n",
       "        [ 2.30696365e-03,  2.12059446e-02,  6.81159705e-03,\n",
       "         -6.69911724e-03, -1.42363302e-02,  1.45281745e-02,\n",
       "         -1.42734834e-03, -1.33572074e-02, -1.69312643e-02,\n",
       "          1.15983683e-02],\n",
       "        [ 1.14561121e-03,  1.85610130e-02,  6.59132017e-03,\n",
       "         -6.76682752e-03, -1.48271431e-02,  1.39730674e-02,\n",
       "         -2.43227245e-03, -1.21753281e-02, -1.65734595e-02,\n",
       "          1.02662400e-02],\n",
       "        [ 7.92703752e-04,  1.80080024e-02,  6.68258949e-03,\n",
       "         -6.17435219e-03, -1.50713946e-02,  1.39366900e-02,\n",
       "         -1.97334412e-03, -1.17024466e-02, -1.67075029e-02,\n",
       "          1.06619897e-02],\n",
       "        [ 7.96456767e-04,  1.94683202e-02,  6.58113596e-03,\n",
       "         -6.80228084e-03, -1.49730779e-02,  1.57328568e-02,\n",
       "         -1.95856416e-03, -1.22953633e-02, -1.79556123e-02,\n",
       "          9.97450805e-03],\n",
       "        [ 1.35262216e-03,  1.99022043e-02,  7.77471410e-03,\n",
       "         -6.41603609e-03, -1.54721246e-02,  1.48739978e-02,\n",
       "         -1.43824131e-03, -1.32407079e-02, -1.71589576e-02,\n",
       "          1.04426854e-02],\n",
       "        [ 1.07225780e-03,  1.99489699e-02,  7.01328734e-03,\n",
       "         -6.80145256e-03, -1.48043586e-02,  1.52047045e-02,\n",
       "         -1.89746192e-03, -1.28247259e-02, -1.73125098e-02,\n",
       "          1.02370272e-02],\n",
       "        [ 4.34500507e-04,  1.92903172e-02,  7.07888027e-03,\n",
       "         -5.49938147e-03, -1.38964026e-02,  1.34443034e-02,\n",
       "         -1.57681409e-03, -1.14224978e-02, -1.62057988e-02,\n",
       "          1.04384320e-02],\n",
       "        [ 1.89424046e-03,  1.92796771e-02,  7.27657767e-03,\n",
       "         -6.22671195e-03, -1.39151789e-02,  1.38079923e-02,\n",
       "         -1.24191530e-03, -1.20917531e-02, -1.54676580e-02,\n",
       "          8.93596837e-03],\n",
       "        [ 1.33177405e-03,  1.65317771e-02,  6.40078667e-03,\n",
       "         -5.69653267e-03, -1.27695322e-02,  1.24422891e-02,\n",
       "         -1.56612000e-03, -1.04434395e-02, -1.51336277e-02,\n",
       "          8.72849991e-03],\n",
       "        [ 1.14042578e-03,  1.72192161e-02,  5.89153696e-03,\n",
       "         -6.24639249e-03, -1.31516277e-02,  1.24874353e-02,\n",
       "         -1.88355497e-03, -1.16856648e-02, -1.57345866e-02,\n",
       "          9.28171644e-03],\n",
       "        [ 7.13335737e-04,  1.75692599e-02,  6.67779080e-03,\n",
       "         -5.81896895e-03, -1.39656871e-02,  1.37881836e-02,\n",
       "         -2.11322394e-03, -1.19700029e-02, -1.67866998e-02,\n",
       "          9.66044915e-03],\n",
       "        [ 6.35287840e-04,  1.78600045e-02,  7.35360306e-03,\n",
       "         -5.47826986e-03, -1.33159774e-02,  1.47464299e-02,\n",
       "         -2.53138165e-03, -1.10678598e-02, -1.67343752e-02,\n",
       "          1.00253755e-02],\n",
       "        [ 1.75939036e-03,  2.00968980e-02,  7.51659172e-03,\n",
       "         -6.52295864e-03, -1.55069142e-02,  1.47609222e-02,\n",
       "         -1.68543920e-03, -1.39646042e-02, -1.85963419e-02,\n",
       "          1.17870817e-02],\n",
       "        [ 1.56359516e-03,  2.01042102e-02,  7.41245657e-03,\n",
       "         -6.63649153e-03, -1.51570237e-02,  1.46926578e-02,\n",
       "         -1.50666878e-03, -1.26622741e-02, -1.79490833e-02,\n",
       "          9.46982478e-03],\n",
       "        [ 6.48042331e-04,  1.76580564e-02,  6.08825804e-03,\n",
       "         -6.52692677e-03, -1.35911908e-02,  1.41515185e-02,\n",
       "         -2.44238890e-03, -1.17975572e-02, -1.56379043e-02,\n",
       "          1.02950631e-02],\n",
       "        [ 6.49939089e-04,  1.89398151e-02,  7.61231433e-03,\n",
       "         -5.86681534e-03, -1.50766463e-02,  1.41371611e-02,\n",
       "         -2.03464289e-03, -1.13463990e-02, -1.76104358e-02,\n",
       "          1.01987702e-02],\n",
       "        [ 4.56294416e-04,  1.78050509e-02,  6.06647973e-03,\n",
       "         -6.12208140e-03, -1.30551156e-02,  1.33577306e-02,\n",
       "         -1.62914027e-03, -1.18635862e-02, -1.55095993e-02,\n",
       "          9.52566285e-03],\n",
       "        [ 1.07793515e-03,  1.79774412e-02,  6.23831404e-03,\n",
       "         -5.92221308e-03, -1.29947890e-02,  1.33197977e-02,\n",
       "         -1.84564819e-03, -1.19964077e-02, -1.57731631e-02,\n",
       "          9.75953281e-03],\n",
       "        [ 1.23622890e-03,  1.67101448e-02,  6.01113246e-03,\n",
       "         -6.22749269e-03, -1.33287379e-02,  1.35566972e-02,\n",
       "         -1.57492973e-03, -1.11964820e-02, -1.48348111e-02,\n",
       "          9.38123229e-03],\n",
       "        [ 1.08338540e-03,  1.80616269e-02,  5.91055361e-03,\n",
       "         -5.38147123e-03, -1.38258298e-02,  1.35099369e-02,\n",
       "         -9.40977465e-04, -1.10826857e-02, -1.54766275e-02,\n",
       "          8.51836369e-03],\n",
       "        [ 1.24314312e-03,  1.70754939e-02,  6.78010071e-03,\n",
       "         -5.14083876e-03, -1.24269815e-02,  1.32577987e-02,\n",
       "         -2.74183812e-03, -1.07674041e-02, -1.49687531e-02,\n",
       "          1.09407380e-02],\n",
       "        [ 4.89643170e-04,  1.76569630e-02,  5.27873738e-03,\n",
       "         -6.00002554e-03, -1.34779150e-02,  1.35504363e-02,\n",
       "         -2.34559234e-03, -1.16237680e-02, -1.45049933e-02,\n",
       "          1.00275757e-02],\n",
       "        [ 8.58395701e-04,  1.67249311e-02,  5.98190759e-03,\n",
       "         -5.78686155e-03, -1.38325857e-02,  1.35252974e-02,\n",
       "         -2.71152011e-03, -1.03989973e-02, -1.60297363e-02,\n",
       "          8.50643413e-03],\n",
       "        [ 1.33146674e-03,  1.78881103e-02,  6.20264835e-03,\n",
       "         -6.31024157e-03, -1.52356414e-02,  1.43969416e-02,\n",
       "         -3.53013593e-03, -1.26672498e-02, -1.75671877e-02,\n",
       "          9.66888841e-03],\n",
       "        [ 1.93341194e-03,  2.10864860e-02,  8.07400475e-03,\n",
       "         -6.99427371e-03, -1.58487610e-02,  1.70290830e-02,\n",
       "         -1.18230044e-03, -1.31224018e-02, -1.88341201e-02,\n",
       "          1.19480898e-02],\n",
       "        [ 4.40365611e-04,  1.86637577e-02,  6.19083551e-03,\n",
       "         -6.41545601e-03, -1.36300157e-02,  1.44598220e-02,\n",
       "         -1.30411575e-03, -1.16909877e-02, -1.58278279e-02,\n",
       "          9.66402702e-03],\n",
       "        [ 7.13593060e-04,  1.87245506e-02,  6.57174773e-03,\n",
       "         -5.38969530e-03, -1.43489416e-02,  1.33711462e-02,\n",
       "         -1.51117611e-03, -1.17623750e-02, -1.66891388e-02,\n",
       "          1.02784104e-02],\n",
       "        [ 4.24891233e-04,  1.69408088e-02,  6.51417295e-03,\n",
       "         -5.29910633e-03, -1.36213304e-02,  1.36098420e-02,\n",
       "         -2.01282987e-03, -1.12442713e-02, -1.66013883e-02,\n",
       "          9.48820578e-03],\n",
       "        [ 8.25756921e-04,  1.67257993e-02,  5.54220534e-03,\n",
       "         -6.42000007e-03, -1.36886838e-02,  1.25500894e-02,\n",
       "         -1.22097774e-03, -1.13620231e-02, -1.50034268e-02,\n",
       "          1.00349973e-02],\n",
       "        [ 8.23338979e-04,  1.78356753e-02,  7.17162429e-03,\n",
       "         -5.48756393e-03, -1.36946070e-02,  1.49625118e-02,\n",
       "         -3.09912853e-03, -1.10452106e-02, -1.64495132e-02,\n",
       "          9.08586973e-03],\n",
       "        [ 1.40401351e-03,  1.77816658e-02,  5.66352018e-03,\n",
       "         -5.12192550e-03, -1.25815588e-02,  1.21426158e-02,\n",
       "         -2.58217380e-03, -1.11149135e-02, -1.58264247e-02,\n",
       "          9.42000973e-03],\n",
       "        [ 1.88554733e-03,  1.83859867e-02,  5.49941021e-03,\n",
       "         -6.06521187e-03, -1.44054942e-02,  1.30980507e-02,\n",
       "         -7.52106857e-04, -1.13178466e-02, -1.44237574e-02,\n",
       "          9.77264953e-03],\n",
       "        [ 2.02380157e-04,  1.96333437e-02,  7.17179393e-03,\n",
       "         -7.07061623e-03, -1.35719032e-02,  1.35410837e-02,\n",
       "         -1.34391783e-03, -1.16286084e-02, -1.70627545e-02,\n",
       "          1.03242689e-02],\n",
       "        [ 1.02999923e-03,  2.00762910e-02,  7.26267849e-03,\n",
       "         -7.76367980e-03, -1.51408203e-02,  1.62614762e-02,\n",
       "         -7.49246212e-04, -1.37818679e-02, -1.80354204e-02,\n",
       "          1.13232290e-02],\n",
       "        [ 1.39501790e-03,  2.14630342e-02,  6.83068734e-03,\n",
       "         -7.28237712e-03, -1.55538156e-02,  1.53590522e-02,\n",
       "         -2.43756329e-03, -1.30714011e-02, -1.79126686e-02,\n",
       "          1.13114293e-02],\n",
       "        [ 1.75788994e-03,  1.97323534e-02,  7.91436211e-03,\n",
       "         -7.14907220e-03, -1.46481052e-02,  1.44542620e-02,\n",
       "         -1.70177962e-03, -1.33408661e-02, -1.67825535e-02,\n",
       "          1.05608533e-02],\n",
       "        [ 1.12520553e-03,  1.81412682e-02,  6.58906298e-03,\n",
       "         -6.22857257e-03, -1.27484132e-02,  1.23740251e-02,\n",
       "         -2.15385526e-03, -1.10973842e-02, -1.57352097e-02,\n",
       "          1.02099958e-02],\n",
       "        [ 1.91432203e-03,  1.93752185e-02,  7.23366000e-03,\n",
       "         -6.64694063e-03, -1.50408916e-02,  1.39459187e-02,\n",
       "         -1.13784854e-03, -1.26855333e-02, -1.63776751e-02,\n",
       "          1.17586461e-02],\n",
       "        [ 1.23662726e-03,  1.99267414e-02,  6.88935142e-03,\n",
       "         -5.83506733e-03, -1.37921663e-02,  1.45060029e-02,\n",
       "         -8.70139161e-04, -1.21146853e-02, -1.76840872e-02,\n",
       "          9.42637410e-03],\n",
       "        [ 1.02926599e-03,  1.93709691e-02,  7.64925687e-03,\n",
       "         -6.17083963e-03, -1.43966243e-02,  1.56534812e-02,\n",
       "         -2.49239228e-03, -1.27550279e-02, -1.82353176e-02,\n",
       "          1.03688624e-02],\n",
       "        [ 1.15969939e-03,  1.86674787e-02,  7.23948379e-03,\n",
       "         -5.46149732e-03, -1.36507763e-02,  1.31943728e-02,\n",
       "         -1.43455129e-03, -1.14996655e-02, -1.60230924e-02,\n",
       "          9.63362389e-03],\n",
       "        [ 1.90573601e-05,  1.82131530e-02,  7.28928818e-03,\n",
       "         -6.23301883e-03, -1.50203374e-02,  1.32716822e-02,\n",
       "         -8.70029950e-04, -1.26531919e-02, -1.64968798e-02,\n",
       "          1.01324382e-02],\n",
       "        [ 1.29184823e-03,  1.88011246e-02,  7.10774533e-03,\n",
       "         -6.39029164e-03, -1.37085638e-02,  1.36757122e-02,\n",
       "         -1.97390108e-03, -1.22664827e-02, -1.69144656e-02,\n",
       "          1.05188224e-02],\n",
       "        [ 1.18536729e-03,  1.78553211e-02,  7.51083967e-03,\n",
       "         -6.45650331e-03, -1.40721000e-02,  1.33796556e-02,\n",
       "         -5.64421185e-04, -1.19311555e-02, -1.56432069e-02,\n",
       "          1.02110635e-02],\n",
       "        [ 9.16294098e-04,  1.72474097e-02,  6.69883878e-03,\n",
       "         -5.56347270e-03, -1.34016440e-02,  1.29567818e-02,\n",
       "         -1.46865304e-03, -1.09517104e-02, -1.53701108e-02,\n",
       "          8.75871766e-03],\n",
       "        [ 1.36176013e-03,  2.09349672e-02,  7.97889932e-03,\n",
       "         -6.54253579e-03, -1.49926638e-02,  1.47721343e-02,\n",
       "         -1.93717536e-03, -1.31921204e-02, -1.85771658e-02,\n",
       "          1.14191741e-02],\n",
       "        [ 6.84293049e-04,  1.86730773e-02,  7.69395832e-03,\n",
       "         -6.32028581e-03, -1.27514342e-02,  1.42679722e-02,\n",
       "         -2.08033526e-03, -1.14744675e-02, -1.57298574e-02,\n",
       "          9.46788266e-03],\n",
       "        [ 4.97102555e-04,  1.60386689e-02,  5.20176485e-03,\n",
       "         -4.40826803e-03, -1.22155122e-02,  1.18218477e-02,\n",
       "         -1.55871344e-03, -9.61829283e-03, -1.45141473e-02,\n",
       "          8.49325993e-03],\n",
       "        [ 1.19773343e-03,  1.97971463e-02,  8.42448905e-03,\n",
       "         -5.88451250e-03, -1.49581397e-02,  1.47140849e-02,\n",
       "         -2.60425754e-03, -1.24403540e-02, -1.67385678e-02,\n",
       "          1.02110592e-02],\n",
       "        [ 9.33062658e-04,  1.80956216e-02,  6.73675196e-03,\n",
       "         -4.29804324e-03, -1.26846953e-02,  1.25101795e-02,\n",
       "         -2.10493916e-03, -1.09640888e-02, -1.58307477e-02,\n",
       "          8.78977978e-03],\n",
       "        [ 1.34517421e-03,  1.95275014e-02,  7.20761879e-03,\n",
       "         -6.91620041e-03, -1.55108690e-02,  1.55384810e-02,\n",
       "         -1.58355419e-03, -1.35638948e-02, -1.79958281e-02,\n",
       "          1.13869381e-02],\n",
       "        [ 3.12146931e-04,  1.78133122e-02,  7.76844551e-03,\n",
       "         -5.57061554e-03, -1.32091856e-02,  1.34680309e-02,\n",
       "         -1.35878430e-03, -1.14977895e-02, -1.58691829e-02,\n",
       "          1.04668885e-02],\n",
       "        [ 1.20288405e-03,  1.85136060e-02,  7.38003209e-03,\n",
       "         -5.47903003e-03, -1.39351137e-02,  1.35256766e-02,\n",
       "         -1.76954305e-03, -1.20931965e-02, -1.64041023e-02,\n",
       "          9.67363171e-03],\n",
       "        [ 1.16353466e-03,  2.12465435e-02,  7.11891655e-03,\n",
       "         -5.75640357e-03, -1.54036240e-02,  1.39713421e-02,\n",
       "         -2.03472549e-03, -1.16222990e-02, -1.76776196e-02,\n",
       "          1.14031154e-02],\n",
       "        [-1.63714624e-04,  1.85844537e-02,  6.05281034e-03,\n",
       "         -6.21717845e-03, -1.39180767e-02,  1.44592153e-02,\n",
       "         -1.28169184e-03, -1.13903853e-02, -1.72823685e-02,\n",
       "          9.95474448e-03],\n",
       "        [ 2.49768952e-04,  2.00411267e-02,  7.19177578e-03,\n",
       "         -5.94527808e-03, -1.41800911e-02,  1.45347374e-02,\n",
       "         -1.40738042e-03, -1.05711341e-02, -1.64239314e-02,\n",
       "          9.96392277e-03],\n",
       "        [ 1.52227734e-03,  2.03085644e-02,  7.14388875e-03,\n",
       "         -6.89675037e-03, -1.54792437e-02,  1.39542864e-02,\n",
       "         -1.79907573e-03, -1.25289693e-02, -1.67154451e-02,\n",
       "          1.14408291e-02],\n",
       "        [ 7.62986048e-04,  1.74005673e-02,  6.12558139e-03,\n",
       "         -6.14165426e-03, -1.33831768e-02,  1.32502248e-02,\n",
       "         -2.09252381e-03, -9.75669703e-03, -1.41693052e-02,\n",
       "          9.30850238e-03],\n",
       "        [ 1.99246227e-03,  2.11518100e-02,  7.58154489e-03,\n",
       "         -7.09701503e-03, -1.66197899e-02,  1.50328610e-02,\n",
       "         -1.87263083e-03, -1.30701230e-02, -1.89224887e-02,\n",
       "          1.14727589e-02],\n",
       "        [ 1.19453709e-04,  1.87065973e-02,  7.55971485e-03,\n",
       "         -5.72194018e-03, -1.34781828e-02,  1.38296857e-02,\n",
       "         -6.38808082e-04, -1.14766141e-02, -1.61216521e-02,\n",
       "          1.00876646e-02],\n",
       "        [ 1.45401678e-03,  1.97180737e-02,  7.71498680e-03,\n",
       "         -7.46933036e-03, -1.60126516e-02,  1.53121677e-02,\n",
       "         -2.47760219e-03, -1.41139359e-02, -1.80147746e-02,\n",
       "          1.07508384e-02],\n",
       "        [-1.37245060e-04,  1.86809534e-02,  8.02762024e-03,\n",
       "         -6.19128052e-03, -1.45357055e-02,  1.40016360e-02,\n",
       "         -1.45403455e-03, -1.22454238e-02, -1.72364760e-02,\n",
       "          1.04124894e-02],\n",
       "        [ 2.71794875e-03,  2.15861121e-02,  8.18556416e-03,\n",
       "         -7.91922819e-03, -1.58281581e-02,  1.54438478e-02,\n",
       "         -3.22748541e-03, -1.35559412e-02, -1.90198165e-02,\n",
       "          1.14751352e-02],\n",
       "        [ 1.06604755e-03,  2.03879630e-02,  7.24701913e-03,\n",
       "         -6.18508974e-03, -1.49196773e-02,  1.52567497e-02,\n",
       "         -2.25576116e-03, -1.31427157e-02, -1.83778999e-02,\n",
       "          1.12886239e-02],\n",
       "        [ 8.65469367e-04,  2.05191849e-02,  6.96004541e-03,\n",
       "         -6.77091776e-03, -1.41176647e-02,  1.41917804e-02,\n",
       "         -1.83012403e-03, -1.37885002e-02, -1.71344222e-02,\n",
       "          1.11369189e-02],\n",
       "        [ 5.98136971e-04,  1.55970249e-02,  5.82421009e-03,\n",
       "         -5.70368069e-03, -1.18423941e-02,  1.14637453e-02,\n",
       "         -2.27308423e-03, -9.16524506e-03, -1.40366004e-02,\n",
       "          7.50830214e-03],\n",
       "        [ 1.45996918e-03,  1.87306034e-02,  7.25939749e-03,\n",
       "         -6.04483567e-03, -1.38797095e-02,  1.40260895e-02,\n",
       "         -1.62015382e-03, -1.19418650e-02, -1.57033472e-02,\n",
       "          1.03125317e-02],\n",
       "        [ 1.74561109e-03,  1.80601990e-02,  6.59143723e-03,\n",
       "         -6.27689126e-03, -1.25598859e-02,  1.21866289e-02,\n",
       "         -2.14921720e-03, -1.10829876e-02, -1.51178919e-02,\n",
       "          9.29905468e-03],\n",
       "        [ 1.61084188e-03,  1.97803703e-02,  7.35116224e-03,\n",
       "         -6.68257634e-03, -1.50582612e-02,  1.49822029e-02,\n",
       "         -1.74473300e-03, -1.27012981e-02, -1.83188086e-02,\n",
       "          9.87025857e-03],\n",
       "        [ 1.54854476e-04,  1.84387961e-02,  7.43251665e-03,\n",
       "         -6.40356269e-03, -1.39673118e-02,  1.30592053e-02,\n",
       "         -1.25853724e-03, -1.08727973e-02, -1.50613252e-02,\n",
       "          1.05635085e-02],\n",
       "        [ 4.89239511e-04,  1.99298923e-02,  7.06523728e-03,\n",
       "         -5.91372636e-03, -1.46162633e-02,  1.39162444e-02,\n",
       "         -2.34323554e-03, -1.30107436e-02, -1.72962389e-02,\n",
       "          1.10115107e-02],\n",
       "        [ 1.04719998e-03,  1.83783763e-02,  7.37649760e-03,\n",
       "         -5.12355133e-03, -1.43553703e-02,  1.31626826e-02,\n",
       "         -1.78712003e-03, -1.06830928e-02, -1.51456041e-02,\n",
       "          8.74065858e-03],\n",
       "        [ 1.60390989e-03,  2.00438880e-02,  8.15978630e-03,\n",
       "         -7.07832474e-03, -1.45264340e-02,  1.48250824e-02,\n",
       "         -1.83583239e-03, -1.31342133e-02, -1.75117550e-02,\n",
       "          1.06244773e-02],\n",
       "        [ 7.13085839e-04,  1.91719763e-02,  7.10008607e-03,\n",
       "         -5.67283944e-03, -1.46453442e-02,  1.40127376e-02,\n",
       "         -1.80548934e-03, -1.25682141e-02, -1.69880689e-02,\n",
       "          1.02056348e-02],\n",
       "        [ 4.74917314e-04,  1.85254886e-02,  6.80742158e-03,\n",
       "         -6.82678920e-03, -1.49580428e-02,  1.49038525e-02,\n",
       "         -8.72086083e-04, -1.22837049e-02, -1.74982222e-02,\n",
       "          1.03473514e-02],\n",
       "        [ 1.54501095e-03,  1.83129334e-02,  6.38527592e-03,\n",
       "         -6.39319317e-03, -1.38466214e-02,  1.40136494e-02,\n",
       "         -1.37550082e-03, -1.16887821e-02, -1.58029064e-02,\n",
       "          1.03281377e-02],\n",
       "        [ 3.05172243e-04,  1.78439118e-02,  5.97174626e-03,\n",
       "         -4.86664344e-03, -1.31411990e-02,  1.34519427e-02,\n",
       "         -2.06543913e-03, -1.08949595e-02, -1.54693320e-02,\n",
       "          8.81441718e-03],\n",
       "        [ 2.05716937e-04,  1.69359325e-02,  6.85433132e-03,\n",
       "         -5.19919322e-03, -1.24471851e-02,  1.20753407e-02,\n",
       "         -1.83467787e-03, -1.00920703e-02, -1.56468100e-02,\n",
       "          8.30918470e-03],\n",
       "        [ 1.14962553e-03,  1.52597574e-02,  5.90598191e-03,\n",
       "         -5.82884699e-03, -1.29007950e-02,  1.23588605e-02,\n",
       "         -1.32017085e-03, -9.24034769e-03, -1.36555194e-02,\n",
       "          8.36506025e-03],\n",
       "        [ 1.12769129e-03,  2.04702334e-02,  6.66827283e-03,\n",
       "         -7.17419820e-03, -1.47265730e-02,  1.46089727e-02,\n",
       "         -1.73496669e-03, -1.34150799e-02, -1.76386073e-02,\n",
       "          1.08998182e-02],\n",
       "        [ 1.83143364e-03,  1.87390805e-02,  5.72130730e-03,\n",
       "         -6.55949002e-03, -1.37023404e-02,  1.49489262e-02,\n",
       "         -2.54748151e-03, -1.23528715e-02, -1.65557420e-02,\n",
       "          1.05904841e-02],\n",
       "        [ 1.33444459e-03,  1.72386257e-02,  6.28197593e-03,\n",
       "         -6.27991302e-03, -1.33678988e-02,  1.32859353e-02,\n",
       "         -1.80004914e-03, -1.12201982e-02, -1.49318974e-02,\n",
       "          9.49070131e-03],\n",
       "        [ 1.88896927e-03,  1.87352115e-02,  7.25640930e-03,\n",
       "         -6.97231940e-03, -1.42893379e-02,  1.50798125e-02,\n",
       "         -7.81390810e-04, -1.29666129e-02, -1.78182356e-02,\n",
       "          1.06143384e-02],\n",
       "        [ 8.09990937e-04,  2.23091703e-02,  8.46094800e-03,\n",
       "         -7.08671266e-03, -1.57292228e-02,  1.61094112e-02,\n",
       "         -2.40557263e-03, -1.30488455e-02, -1.80196240e-02,\n",
       "          1.11234029e-02],\n",
       "        [ 2.01208703e-03,  2.24123460e-02,  8.03783166e-03,\n",
       "         -6.35819692e-03, -1.54906856e-02,  1.64021203e-02,\n",
       "         -1.10047253e-03, -1.35585654e-02, -1.92594811e-02,\n",
       "          1.12550776e-02],\n",
       "        [ 1.09801725e-03,  1.80461999e-02,  7.45070302e-03,\n",
       "         -5.91808259e-03, -1.28331430e-02,  1.40830046e-02,\n",
       "         -2.39475654e-03, -1.11354666e-02, -1.61845593e-02,\n",
       "          1.01964361e-02],\n",
       "        [ 1.47784782e-03,  1.63434615e-02,  5.65334382e-03,\n",
       "         -5.77436012e-03, -1.30790045e-02,  1.27639406e-02,\n",
       "         -2.13220069e-03, -1.12203009e-02, -1.56232790e-02,\n",
       "          9.28636155e-03],\n",
       "        [ 1.53224338e-03,  2.08767607e-02,  7.60479402e-03,\n",
       "         -6.32222001e-03, -1.57486941e-02,  1.53362769e-02,\n",
       "         -3.05230227e-03, -1.39072031e-02, -1.73954177e-02,\n",
       "          1.08732377e-02],\n",
       "        [ 1.26682927e-03,  1.80251373e-02,  6.80242437e-03,\n",
       "         -4.75274948e-03, -1.17930868e-02,  1.27019158e-02,\n",
       "         -2.05217237e-03, -1.11628404e-02, -1.47308786e-02,\n",
       "          8.56997310e-03],\n",
       "        [ 8.38239558e-04,  2.02570511e-02,  8.31873649e-03,\n",
       "         -7.08640837e-03, -1.51520774e-02,  1.54385846e-02,\n",
       "         -1.75780226e-03, -1.24599108e-02, -1.80064220e-02,\n",
       "          1.08049992e-02],\n",
       "        [ 1.11346221e-03,  1.88726591e-02,  7.31882967e-03,\n",
       "         -6.31675928e-03, -1.47899244e-02,  1.47965375e-02,\n",
       "         -2.16244960e-03, -1.18174918e-02, -1.76014706e-02,\n",
       "          9.82615411e-03],\n",
       "        [ 1.78971892e-03,  2.04818381e-02,  8.50339170e-03,\n",
       "         -7.54486411e-03, -1.65987696e-02,  1.56706561e-02,\n",
       "         -1.71009315e-03, -1.34147590e-02, -1.81740365e-02,\n",
       "          1.20183620e-02]]),\n",
       " 'b1': array([-1.03777325e-04, -4.88440222e-05,  1.06481259e-04,  4.67846206e-05,\n",
       "         8.06153366e-06,  2.36129480e-04, -5.44453727e-05, -3.34554784e-05,\n",
       "         3.70399178e-05, -1.71878511e-05, -4.41890080e-06, -1.80518747e-04,\n",
       "         2.83815176e-04, -1.16859127e-04, -1.60255063e-04, -1.39392036e-04,\n",
       "        -2.61736695e-04, -2.74200005e-04,  8.66230820e-05,  1.56345941e-04,\n",
       "         2.18719656e-04, -1.29156597e-04,  3.18938831e-04,  2.92640578e-06,\n",
       "        -2.24254997e-04, -1.67915175e-04, -3.58817260e-04, -1.33866642e-04,\n",
       "         1.48353259e-04, -1.31220332e-04,  1.48896611e-04,  4.37865921e-05,\n",
       "        -3.40317641e-05,  1.99932195e-04,  1.05730074e-04,  1.41254191e-04,\n",
       "        -2.78574142e-04,  1.93887608e-04,  2.42940743e-04,  8.71139605e-06,\n",
       "        -2.05461070e-04,  2.49388812e-04,  3.94874746e-04, -8.66830163e-06,\n",
       "         1.31263995e-04, -1.31193971e-04,  1.06029177e-04,  2.15615117e-04,\n",
       "         1.03921494e-04,  3.65434651e-04, -9.53524193e-05,  1.62415539e-04,\n",
       "         1.09704281e-04, -1.96582342e-04,  2.84703994e-04,  8.40313419e-05,\n",
       "         1.68294747e-04, -8.01531996e-05,  2.08949125e-04, -2.43025404e-04,\n",
       "        -3.63406016e-05, -2.07615436e-04, -2.85335560e-04, -9.80822179e-05,\n",
       "        -8.25857427e-05, -1.13958265e-04,  1.73796266e-05, -1.17079964e-04,\n",
       "         2.30840769e-05,  1.09774305e-04, -4.69688501e-04, -2.00762820e-04,\n",
       "         4.75562025e-04, -7.53513163e-05, -5.60735103e-05,  1.59644742e-05,\n",
       "        -4.46883774e-05, -2.75448286e-05,  9.77269465e-05,  4.51922482e-04,\n",
       "        -1.90013800e-04, -1.08910641e-04,  2.41704043e-04,  2.51971599e-05,\n",
       "        -2.16873062e-04,  3.47006122e-04,  8.01954059e-06, -3.49280924e-04,\n",
       "        -1.67824759e-04, -7.92173438e-06, -2.02026236e-04,  1.68090892e-04,\n",
       "        -1.32119915e-04,  3.94576389e-04,  1.19545263e-04,  5.61404008e-04,\n",
       "         1.81284427e-04,  4.77361439e-05,  2.15876774e-04,  2.46631515e-05]),\n",
       " 'b2': array([ 0.00220488,  0.03699548,  0.01362714, -0.01224223, -0.02810256,\n",
       "         0.02793865, -0.00382121, -0.0236622 , -0.0328334 ,  0.01989544])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-04945db19e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#记录学习过程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "## 执行小批次学习\n",
    "import numpy as np\n",
    "\n",
    "(x_train, t_train),(x_test, t_test) = load_mnist(normalize =True, one_hot_label=True)\n",
    "train_loss_list =[]\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "##hyperparameters\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network_100 = TwoLayerNet(input_size = 784, hidden_size=50, output_size= 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grads = network_100.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    #更新参数\n",
    "    for key in ('W1','b1','W2','b2'):\n",
    "        network_100.params[key] -= learning_rate *grads[key]\n",
    "        \n",
    "    #记录学习过程\n",
    "    loss = network_100.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    #计算 1 epoch 的辨识准确度\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network_100.accuracy(x_train, t_train)\n",
    "        test_acc = network_100.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('train acc, test acc | '+ str(train_acc)+ ', '+str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoch是一种单位. 1 epoch 是指在学习中, 用完所有训练资料时的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(venv_nlp)",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
